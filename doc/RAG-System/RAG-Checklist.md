# Checklist de V√©rification du Syst√®me RAG

Cette checklist vous permet de v√©rifier que tous les composants du syst√®me RAG sont en place et fonctionnels.

## ‚úÖ Phase 1: Fichiers et Structure

### Modules sources (obligatoires)

- [ ] `src/dyag/commands/create_rag.py` existe
- [ ] `src/dyag/rag_query.py` existe

**V√©rification:**
```bash
ls -la src/dyag/commands/create_rag.py
ls -la src/dyag/rag_query.py
```

### Scripts ex√©cutables (obligatoires)

- [ ] `scripts/index_chunks.py` existe
- [ ] `scripts/example_rag_complete.py` existe

**V√©rification:**
```bash
ls -la scripts/index_chunks.py
ls -la scripts/example_rag_complete.py
```

### Scripts de test (optionnels)

- [ ] `test_create_rag.py` existe
- [ ] `example_create_rag.py` existe
- [ ] `generate_optimal_rag.py` existe

### Documentation (recommand√©e)

- [ ] `doc/rag-quick-start.md` existe ‚≠ê
- [ ] `doc/rag-modules-guide.md` existe
- [ ] `doc/rag-chunks-algo.md` existe
- [ ] `doc/chunks-why.md` existe
- [ ] `doc/chunks-for-management.md` existe
- [ ] `doc/rag-system-summary.md` existe
- [ ] `doc/rag-architecture.puml` existe
- [ ] `doc/rag-checklist.md` existe (ce fichier)

**V√©rification rapide:**
```bash
ls -la doc/rag-*.md
```

### Configuration (obligatoire)

- [ ] `requirements-rag.txt` existe
- [ ] `.env.example` existe
- [ ] `RAG_README.md` existe et est √† jour

---

## ‚úÖ Phase 2: Installation et Configuration

### Installation des d√©pendances

- [ ] Python 3.8+ install√©
- [ ] Pip √† jour

**V√©rification:**
```bash
python --version  # Doit afficher 3.8 ou sup√©rieur
pip --version
```

- [ ] D√©pendances RAG install√©es

**Installation:**
```bash
pip install -r requirements-rag.txt
```

**V√©rification:**
```bash
python -c "import chromadb; print(chromadb.__version__)"
python -c "import sentence_transformers; print(sentence_transformers.__version__)"
python -c "import openai; print(openai.__version__)"
```

**R√©sultat attendu:**
```
0.4.22
2.3.1
1.12.0
```

### Configuration de l'API OpenAI

- [ ] Compte OpenAI cr√©√©
- [ ] Cl√© API obtenue sur https://platform.openai.com/api-keys
- [ ] Fichier `.env` cr√©√© √† la racine

**Cr√©ation du .env:**
```bash
cp .env.example .env
# √âditez .env et ajoutez votre cl√©
```

**Contenu minimal de .env:**
```env
OPENAI_API_KEY=sk-proj-votre-cle-ici
```

**V√©rification:**
```bash
# V√©rifier que le fichier existe
ls -la .env

# V√©rifier que la cl√© est d√©finie (sans afficher la valeur)
python -c "from dotenv import load_dotenv; import os; load_dotenv(); print('OK' if os.getenv('OPENAI_API_KEY') else 'MANQUANT')"
```

**R√©sultat attendu:** `OK`

---

## ‚úÖ Phase 3: Donn√©es et Chunks

### Fichier source disponible

- [ ] Fichier source existe (JSON ou Markdown)

**Exemples de chemins:**
- `examples/test-mygusi/applicationsIA_mini_opt.md`
- `examples/test-mygusi/applicationsIA_mini_normalized.json`

**V√©rification:**
```bash
ls -la examples/test-mygusi/applicationsIA_mini_opt.md
```

### Chunks g√©n√©r√©s

- [ ] Chunks JSONL g√©n√©r√©s

**G√©n√©ration:**
```bash
python -m dyag.commands.create_rag \
    examples/test-mygusi/applicationsIA_mini_opt.md \
    applications_rag_optimal.jsonl
```

**V√©rification:**
```bash
ls -lh applications_rag_optimal.jsonl
wc -l applications_rag_optimal.jsonl  # Doit afficher ~1628 lignes
```

**R√©sultat attendu:**
```
-rw-r--r-- 1 user user 1.8M applications_rag_optimal.jsonl
1628 applications_rag_optimal.jsonl
```

### Test du chunking

- [ ] Module de chunking fonctionne

**Test:**
```bash
python -c "
from dyag.commands.create_rag import RAGCreator
creator = RAGCreator()
print('Module de chunking: OK')
"
```

**R√©sultat attendu:** `Module de chunking: OK`

---

## ‚úÖ Phase 4: Indexation

### Base ChromaDB cr√©√©e

- [ ] ChromaDB install√© correctement
- [ ] Chunks index√©s dans ChromaDB

**Indexation:**
```bash
python scripts/index_chunks.py applications_rag_optimal.jsonl
```

**R√©sultat attendu:**
```
Connexion a ChromaDB: .\chroma_db
Chargement du modele d'embedding: all-MiniLM-L6-v2
Modele charge avec dimension: 384

Chargement des chunks depuis: applications_rag_optimal.jsonl
Chunks charges: 1628

Indexation de 1628 chunks...
...
Indexation terminee:
  - Indexes: 1628
  - Erreurs: 0
  - Taux de reussite: 100.0%
```

### V√©rification de la base

- [ ] R√©pertoire `chroma_db/` existe
- [ ] Collection `applications` existe

**V√©rification:**
```bash
ls -la chroma_db/

python -c "
import chromadb
client = chromadb.PersistentClient(path='./chroma_db')
collection = client.get_collection('applications')
print(f'Chunks indexes: {collection.count()}')
"
```

**R√©sultat attendu:**
```
Chunks indexes: 1628
```

---

## ‚úÖ Phase 5: Questions & R√©ponses

### Module de Q&A fonctionnel

- [ ] Module rag_query importable

**Test:**
```bash
python -c "
from dyag.rag_query import RAGQuerySystem
print('Module de Q&A: OK')
"
```

**R√©sultat attendu:** `Module de Q&A: OK`

### Initialisation du syst√®me

- [ ] RAGQuerySystem s'initialise sans erreur

**Test:**
```bash
python -c "
from dyag.rag_query import RAGQuerySystem
rag = RAGQuerySystem()
stats = rag.get_stats()
print(f'Chunks indexes: {stats[\"total_chunks\"]}')
print(f'Modele LLM: {stats[\"llm_model\"]}')
print('Initialisation: OK')
"
```

**R√©sultat attendu:**
```
Chunks indexes: 1628
Modele LLM: gpt-4o-mini
Initialisation: OK
```

### Test d'une question simple

- [ ] Question pos√©e avec succ√®s
- [ ] R√©ponse g√©n√©r√©e
- [ ] Sources cit√©es

**Test:**
```bash
python -c "
from dyag.rag_query import RAGQuerySystem
rag = RAGQuerySystem()
result = rag.ask('Qui h√©berge GIDAF ?')
print('Question:', result['question'])
print('R√©ponse:', result['answer'][:100] + '...')
print('Sources:', len(result['sources']), 'chunks')
print('Tokens:', result['tokens_used'])
print('Test Q&A: OK')
"
```

**R√©sultat attendu:**
```
Question: Qui h√©berge GIDAF ?
R√©ponse: GIDAF est h√©berg√© par le BRGM...
Sources: 5 chunks
Tokens: 342
Test Q&A: OK
```

### Mode interactif

- [ ] Mode interactif lance sans erreur

**Test:**
```bash
python -m dyag.rag_query
# Tapez Ctrl+C pour quitter apr√®s v√©rification
```

**R√©sultat attendu:**
```
Initialisation du systeme RAG...

Statistiques:
  - Chunks indexes: 1628
  - Modele LLM: gpt-4o-mini

Mode interactif - Posez vos questions (Ctrl+C pour quitter)
‚ùì Question: _
```

---

## ‚úÖ Phase 6: Tests Avanc√©s

### Test avec filtrage

- [ ] Filtrage par source_id fonctionne

**Test:**
```bash
python -c "
from dyag.rag_query import RAGQuerySystem
rag = RAGQuerySystem()
result = rag.ask(
    'Quelle est la description ?',
    filter_metadata={'source_id': '383'}
)
print('Filtrage: OK')
print('Sources:', result['sources'])
"
```

### Test avec param√®tres personnalis√©s

- [ ] Param√®tre n_chunks fonctionne
- [ ] Param√®tre temperature fonctionne

**Test:**
```bash
python -c "
from dyag.rag_query import RAGQuerySystem
rag = RAGQuerySystem()

# Test n_chunks
result1 = rag.ask('Question test', n_chunks=10)
print(f'n_chunks=10: {len(result1[\"sources\"])} sources')

# Test temperature
result2 = rag.ask('Question test', temperature=0.0)
print(f'temperature=0.0: OK')

print('Parametres personnalises: OK')
"
```

### Test du script complet

- [ ] Script example_rag_complete.py s'ex√©cute

**Test:**
```bash
python scripts/example_rag_complete.py
# Suivez les √©tapes du script
# Ctrl+C pour interrompre
```

---

## ‚úÖ Phase 7: Documentation

### Lecture de la documentation

- [ ] `rag-quick-start.md` lu ‚≠ê
- [ ] `rag-modules-guide.md` parcouru
- [ ] `rag-system-summary.md` consult√©

### Compr√©hension du syst√®me

- [ ] Comprendre les 3 phases (chunking, indexation, Q&A)
- [ ] Savoir cr√©er des chunks
- [ ] Savoir indexer dans ChromaDB
- [ ] Savoir poser des questions

---

## ‚úÖ Phase 8: Optimisations (Optionnel)

### Performance

- [ ] Temps de r√©ponse < 5 secondes
- [ ] Indexation termin√©e en < 5 minutes

**Si trop lent:**
- Utiliser `batch_size` plus grand pour indexation
- R√©duire `n_chunks` pour Q&A
- Utiliser GPU pour embeddings

### Co√ªts

- [ ] Co√ªt par question estim√©
- [ ] Budget mensuel d√©fini

**Estimation:**
```bash
python -c "
# Exemple: 500 questions/mois
questions_par_mois = 500
cout_par_question = 0.01  # USD
cout_mensuel = questions_par_mois * cout_par_question
print(f'Estimation mensuelle: ${cout_mensuel:.2f}')
"
```

### Monitoring

- [ ] Tokens utilis√©s track√©s
- [ ] Logs activ√©s si n√©cessaire

**Activer les logs:**
```python
from loguru import logger
logger.add("rag.log", rotation="1 day")
```

---

## üéØ Checklist Rapide (D√©marrage 5 min)

Pour un test rapide du syst√®me complet:

```bash
# 1. Installer (1 min)
pip install -r requirements-rag.txt

# 2. Configurer (30 sec)
cp .env.example .env
# √âditez .env avec votre cl√© API

# 3. Indexer (2 min)
python scripts/index_chunks.py applications_rag_optimal.jsonl

# 4. Tester (1 min)
python -m dyag.rag_query
# Posez une question: "Qui h√©berge GIDAF ?"
```

---

## üìä R√©sum√© de V√©rification

Cochez toutes les cases pour confirmer que votre syst√®me est op√©rationnel:

**Essentiel (minimum viable):**
- [ ] Modules sources install√©s (create_rag.py, rag_query.py)
- [ ] D√©pendances install√©es (requirements-rag.txt)
- [ ] Cl√© API OpenAI configur√©e (.env)
- [ ] Chunks g√©n√©r√©s (applications_rag_optimal.jsonl)
- [ ] ChromaDB index√©e (1628 chunks)
- [ ] Test Q&A r√©ussi

**Recommand√© (meilleure exp√©rience):**
- [ ] Documentation lue (rag-quick-start.md)
- [ ] Scripts de test ex√©cut√©s
- [ ] Param√®tres personnalis√©s test√©s
- [ ] Diagrammes d'architecture consult√©s

**Avanc√© (optimisations):**
- [ ] Logs configur√©s
- [ ] Co√ªts estim√©s
- [ ] Architecture hybride explor√©e
- [ ] Interface web cr√©√©e

---

## üÜò D√©pannage

Si une case n'est pas coch√©e:

1. **Module manquant** ‚Üí V√©rifiez que tous les fichiers sont pr√©sents
2. **D√©pendance manquante** ‚Üí R√©installez avec `pip install -r requirements-rag.txt`
3. **API OpenAI** ‚Üí V√©rifiez `.env` et validez la cl√© sur platform.openai.com
4. **Chunks non g√©n√©r√©s** ‚Üí Ex√©cutez `python -m dyag.commands.create_rag ...`
5. **ChromaDB vide** ‚Üí Ex√©cutez `python scripts/index_chunks.py ...`
6. **Q&A √©choue** ‚Üí V√©rifiez les logs et la connexion OpenAI

Consultez `doc/rag-quick-start.md` section "R√©solution de Probl√®mes".

---

## ‚úÖ Validation Finale

Ex√©cutez ce test complet pour valider l'ensemble du syst√®me:

```bash
# Test unitaire complet
python -c "
print('=== TEST COMPLET DU SYSTEME RAG ===\n')

# 1. Modules
print('1. Verification des modules...')
from dyag.commands.create_rag import RAGCreator
from dyag.rag_query import RAGQuerySystem
print('   ‚úì Modules importes\n')

# 2. ChromaDB
print('2. Verification ChromaDB...')
import chromadb
client = chromadb.PersistentClient(path='./chroma_db')
collection = client.get_collection('applications')
count = collection.count()
print(f'   ‚úì {count} chunks indexes\n')

# 3. RAG System
print('3. Verification RAG System...')
rag = RAGQuerySystem()
stats = rag.get_stats()
print(f'   ‚úì Systeme initialise')
print(f'   ‚úì Modele: {stats[\"llm_model\"]}\n')

# 4. Test Q&A
print('4. Test question/reponse...')
result = rag.ask('Test system')
print(f'   ‚úì Reponse generee')
print(f'   ‚úì Sources: {len(result[\"sources\"])} chunks')
print(f'   ‚úì Tokens: {result[\"tokens_used\"]}\n')

print('=== SYSTEME OPERATIONNEL ===')
print('Tout est pret ! Consultez doc/rag-quick-start.md pour commencer.')
"
```

**R√©sultat attendu:**
```
=== TEST COMPLET DU SYSTEME RAG ===

1. Verification des modules...
   ‚úì Modules importes

2. Verification ChromaDB...
   ‚úì 1628 chunks indexes

3. Verification RAG System...
   ‚úì Systeme initialise
   ‚úì Modele: gpt-4o-mini

4. Test question/reponse...
   ‚úì Reponse generee
   ‚úì Sources: 5 chunks
   ‚úì Tokens: 234

=== SYSTEME OPERATIONNEL ===
Tout est pret ! Consultez doc/rag-quick-start.md pour commencer.
```

---

## üìö Prochaines √âtapes

Une fois toutes les cases coch√©es:

1. **Explorez** ‚Üí Testez diff√©rentes questions
2. **Personnalisez** ‚Üí Ajustez les param√®tres (n_chunks, temperature)
3. **Optimisez** ‚Üí Consultez `doc/chunks-for-management.md` pour dashboards
4. **D√©ployez** ‚Üí Cr√©ez une interface web avec Streamlit

üéâ **F√©licitations ! Votre syst√®me RAG est op√©rationnel !**
