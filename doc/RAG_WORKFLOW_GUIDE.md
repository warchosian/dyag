# Guide Complet : Cr√©er un RAG de Qualit√© avec Dyag

Ce guide vous accompagne pas-√†-pas dans la cr√©ation d'un syst√®me RAG (Retrieval-Augmented Generation) de haute qualit√© √† partir de donn√©es JSON d'applications, en utilisant Dyag via CLI et MCP.

## üìã Table des mati√®res

- [Introduction](#introduction)
- [Pr√©requis](#pr√©requis)
- [Vue d'ensemble du workflow](#vue-densemble-du-workflow)
- [√âtape 1 : Analyse des donn√©es source](#√©tape-1--analyse-des-donn√©es-source)
- [√âtape 2 : Pr√©paration et chunking des donn√©es](#√©tape-2--pr√©paration-et-chunking-des-donn√©es)
- [√âtape 3 : Indexation dans ChromaDB](#√©tape-3--indexation-dans-chromadb)
- [√âtape 4 : Configuration du LLM](#√©tape-4--configuration-du-llm)
- [√âtape 5 : Interrogation du RAG](#√©tape-5--interrogation-du-rag)
- [√âtape 6 : √âvaluation de la qualit√©](#√©tape-6--√©valuation-de-la-qualit√©)
- [√âtape 7 : Am√©lioration it√©rative](#√©tape-7--am√©lioration-it√©rative)
- [Annexes](#annexes)

---

## Introduction

Ce guide couvre **deux workflows** pour cr√©er un syst√®me RAG :

1. **Workflow JSON** (original) : √Ä partir de `applicationsIA_mini_normalized.json`
2. **Workflow Markdown** (nouveau) : √Ä partir de `applicationsIA_mini_opt.md` ‚ú®

Les deux workflows aboutissent au m√™me r√©sultat : un syst√®me RAG capable de r√©pondre intelligemment √† des questions sur les applications du syst√®me d'information fran√ßais.

> üìù **Journal de r√©alisation** : Consultez `doc/RAG_WORKFLOW_JOURNAL.md` pour un exemple complet d'indexation r√©ussie avec le workflow Markdown.

### Qu'est-ce qu'un RAG de qualit√© ?

Un RAG de qualit√© doit :
- ‚úÖ Retrouver les informations pertinentes (haute pr√©cision)
- ‚úÖ G√©n√©rer des r√©ponses exactes et contextualis√©es
- ‚úÖ Citer ses sources avec pr√©cision
- ‚úÖ G√©rer l'absence d'information gracieusement
- ‚úÖ √ätre rapide et efficace

---

## Pr√©requis

### Installation

```bash
# Installation de base
poetry install

# Installation avec support RAG
poetry install -E rag
# ou
pip install -r requirements-rag.txt
```

### Configuration

Cr√©ez un fichier `.env` √† la racine du projet :

```env
# Provider LLM (choisissez-en un)
LLM_PROVIDER=ollama  # GRATUIT - Local
# LLM_PROVIDER=openai  # Payant
# LLM_PROVIDER=anthropic  # Payant

# Configuration Ollama (GRATUIT)
LLM_MODEL=llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# Ou OpenAI (Payant ~$0.01/question)
# OPENAI_API_KEY=sk-proj-votre-cl√©

# Ou Anthropic (Payant ~$0.015/question)
# ANTHROPIC_API_KEY=sk-ant-votre-cl√©

# Configuration ChromaDB
CHROMA_PATH=./chroma_db
EMBEDDING_MODEL=all-MiniLM-L6-v2
```

### Installation d'Ollama (recommand√© - GRATUIT)

```bash
# Windows/Mac/Linux
# T√©l√©chargez depuis https://ollama.com/download

# Puis installez un mod√®le
ollama pull llama3.2

# V√©rifiez qu'Ollama fonctionne
ollama list
```

---

## Vue d'ensemble du workflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    WORKFLOW RAG COMPLET                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. üìä ANALYSE DES DONN√âES
   ‚îî‚îÄ> Comprendre la structure JSON

2. üîß PR√âPARATION & CHUNKING
   ‚îî‚îÄ> dyag prepare-rag
       - Normalisation des donn√©es
       - D√©coupage en chunks optimaux
       - Nettoyage et enrichissement

3. üìá INDEXATION
   ‚îî‚îÄ> dyag index-rag
       - Cr√©ation des embeddings
       - Stockage dans ChromaDB
       - Indexation vectorielle

4. ‚öôÔ∏è CONFIGURATION LLM
   ‚îî‚îÄ> Choix du provider (Ollama/OpenAI/Anthropic)
       - Configuration .env
       - Test de connexion

5. üí¨ INTERROGATION
   ‚îî‚îÄ> dyag query-rag
       - Recherche s√©mantique
       - G√©n√©ration de r√©ponse
       - Citations des sources

6. üìä √âVALUATION
   ‚îî‚îÄ> dyag evaluate-rag
       - Cr√©ation dataset de test
       - M√©triques de qualit√©
       - Analyse des erreurs

7. üîÑ AM√âLIORATION
   ‚îî‚îÄ> It√©ration sur le chunking
       - Ajustement des param√®tres
       - R√©-indexation
       - Re-test
```

---

## √âtape 1 : Analyse des donn√©es source

### 1.1 Examen de la structure JSON

**Commande CLI :**
```bash
# Examiner le fichier JSON
cat examples/test-mygusi/applicationsIA_mini_normalized.json | python -m json.tool | head -100
```

**Structure des donn√©es :**
```json
{
  "applicationsia mini": [
    {
      "id": 1238,
      "nom": "6tzen",
      "nom long": "outil national de dematerialisation...",
      "statut si": "en production",
      "descriptif": "la dematerialisation des procedures...",
      "domaines et sous domaines": [...],
      "sites": [...],
      "acteurs": [...],
      "contacts": [...]
    }
  ]
}
```

### 1.2 Statistiques du dataset

**Commande CLI :**
```bash
# Compter le nombre d'applications
python -c "import json; data=json.load(open('examples/test-mygusi/applicationsIA_mini_normalized.json')); print(f'Nombre d\\'applications: {len(data[\"applicationsia mini\"])}')"
```

**üìä Utilisation via MCP :**
```json
{
  "tool": "dyag_analyze_training",
  "arguments": {
    "applications": "examples/test-mygusi/applicationsIA_mini_normalized.json",
    "training": "training_data.jsonl"
  }
}
```
*Note: Cette commande MCP existe d√©j√†*

### 1.3 Comprendre les champs cl√©s

Les champs les plus importants pour le RAG :
- **`nom`** : Nom court de l'application (identifiant principal)
- **`nom long`** : Description compl√®te du nom
- **`descriptif`** : Texte riche contenant les d√©tails fonctionnels
- **`domaines et sous domaines`** : Contexte m√©tier
- **`statut si`** : √âtat actuel (production, construction, etc.)
- **`sites`** : URLs de l'application
- **`acteurs`** : Organisations responsables

**üí° Conseil :** Ces champs seront utilis√©s pour cr√©er des chunks riches et contextualis√©s.

---

## √âtape 2 : Pr√©paration et chunking des donn√©es

### 2.1 Comprendre le chunking optimal

Le chunking est **crucial** pour la qualit√© du RAG. Un bon chunk doit :
- Contenir une information **compl√®te et autonome**
- Avoir une **taille optimale** (500-2000 tokens)
- Pr√©server le **contexte**
- √âviter les **coupures au milieu d'une phrase**

### 2.2 Strat√©gies de chunking pour les applications

Pour notre fichier JSON d'applications, nous avons **3 strat√©gies** :

#### Strat√©gie A : Un chunk par application (recommand√© pour petites applications)
```
Chunk = {
  "nom": "6tzen",
  "descriptif": "...",
  "domaines": "transports routiers",
  ...
}
```

#### Strat√©gie B : Chunks par section (recommand√© pour grandes applications)
```
Chunk 1 = Informations g√©n√©rales (nom, statut, domaine)
Chunk 2 = Descriptif d√©taill√©
Chunk 3 = Acteurs et contacts
Chunk 4 = Sites et URLs
```

#### Strat√©gie C : Hybride avec overlap
```
Chunk 1 = [Infos g√©n√©rales + d√©but descriptif]
Chunk 2 = [fin Infos g√©n√©rales + descriptif complet + d√©but acteurs] (overlap)
Chunk 3 = [descriptif + acteurs + sites] (overlap)
```

### 2.3 Pr√©paration avec dyag

**Commande CLI :**
```bash
# Cr√©er les chunks avec la strat√©gie optimale
dyag prepare-rag \
  examples/test-mygusi/applicationsIA_mini_normalized.json \
  --output prepared/applications_chunks.jsonl \
  --chunk-strategy semantic \
  --chunk-size 1000 \
  --overlap 200 \
  --add-context \
  --verbose
```

**Param√®tres expliqu√©s :**
- `--chunk-strategy semantic` : D√©coupage intelligent par sections s√©mantiques
- `--chunk-size 1000` : Taille cible de ~1000 tokens par chunk
- `--overlap 200` : 200 tokens de chevauchement entre chunks
- `--add-context` : Ajoute le nom de l'application √† chaque chunk
- `--verbose` : Affiche les d√©tails du traitement

**üìä Utilisation via MCP :**
```json
{
  "tool": "dyag_prepare_rag",
  "arguments": {
    "input": "examples/test-mygusi/applicationsIA_mini_normalized.json",
    "output": "prepared/applications_chunks.jsonl",
    "chunk_strategy": "semantic",
    "chunk_size": 1000,
    "overlap": 200,
    "add_context": true,
    "verbose": true
  }
}
```
*‚ö†Ô∏è Note: Cette commande MCP **n'existe pas encore** et doit √™tre ajout√©e*

### 2.4 V√©rification des chunks cr√©√©s

**Commande CLI :**
```bash
# Examiner les chunks cr√©√©s
head -5 prepared/applications_chunks.jsonl

# Compter les chunks
wc -l prepared/applications_chunks.jsonl

# V√©rifier la taille moyenne des chunks
python -c "
import json
chunks = [json.loads(line) for line in open('prepared/applications_chunks.jsonl')]
avg_len = sum(len(c['content']) for c in chunks) / len(chunks)
print(f'Nombre de chunks: {len(chunks)}')
print(f'Taille moyenne: {avg_len:.0f} caract√®res')
print(f'Min: {min(len(c[\"content\"]) for c in chunks)}')
print(f'Max: {max(len(c[\"content\"]) for c in chunks)}')
"
```

**R√©sultat attendu :**
```
Nombre de chunks: 45
Taille moyenne: 850 caract√®res
Min: 400
Max: 1500
```

**üí° Conseil :** Si la taille moyenne est trop grande (>1500), r√©duisez `--chunk-size`. Si trop petite (<500), augmentez-la.

---

## √âtape 2.5 : Alternative - Workflow Markdown (NOUVEAU) ‚ú®

Si vous avez d√©j√† un fichier Markdown optimis√© (comme `applicationsIA_mini_opt.md`), vous pouvez utiliser directement `prepare-rag` pour le chunker.

### Avantages du workflow Markdown
- ‚úÖ Pas besoin de convertir JSON ‚Üí Markdown
- ‚úÖ Chunking automatique avec gestion du chevauchement
- ‚úÖ Export JSON automatique pour l'indexation
- ‚úÖ Plus rapide si le Markdown existe d√©j√†

### Commande de pr√©paration Markdown

**Commande CLI :**
```bash
# Cr√©er le r√©pertoire
mkdir -p prepared

# Chunker le fichier Markdown
dyag prepare-rag examples/test-mygusi/applicationsIA_mini_opt.md \
  --output prepared/applicationsIA_mini_chunks.jsonl \
  --chunk size \
  --chunk-size 1000 \
  --chunk-overlap 200 \
  --extract-json \
  --verbose
```

**Param√®tres expliqu√©s :**
- `--chunk size` : D√©coupage par taille de caract√®res (recommand√© pour Markdown long)
- `--chunk section` : Alternative pour d√©couper par sections Markdown (# headers)
- `--chunk-size 1000` : Taille cible par chunk
- `--chunk-overlap 200` : Chevauchement entre chunks pour pr√©server le contexte
- `--extract-json` : G√©n√®re aussi un fichier JSON avec m√©tadonn√©es
- `--verbose` : Affiche la progression

**R√©sultat attendu :**
```
‚úì 1010 chunks cr√©√©s
  Taille moyenne: 6244 caract√®res
  Fichiers g√©n√©r√©s:
  - prepared/applicationsIA_mini_chunks.jsonl (Markdown nettoy√©)
  - prepared/applicationsIA_mini_chunks.json (M√©tadonn√©es + chunks)
```

### ‚ö†Ô∏è Probl√®me connu : IDs num√©riques

Le fichier JSON g√©n√©r√© contient des IDs num√©riques qui doivent √™tre convertis en strings pour ChromaDB.

**Script de correction :**
```python
import json

# Charger le JSON
with open('prepared/applicationsIA_mini_chunks.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Convertir les IDs en strings
for chunk in data['chunks']:
    chunk['id'] = f'chunk_{chunk["id"]}'

# Sauvegarder le JSON corrig√©
with open('prepared/applicationsIA_mini_chunks_fixed.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=2)

print("‚úì Fichier corrig√© cr√©√©: prepared/applicationsIA_mini_chunks_fixed.json")
```

**R√©sultat :**
```
‚úì Fichier corrig√© cr√©√©: prepared/applicationsIA_mini_chunks_fixed.json
  IDs: chunk_0, chunk_1, chunk_2...
```

### V√©rification de la structure

```bash
python -c "
import json
data = json.load(open('prepared/applicationsIA_mini_chunks_fixed.json', 'r', encoding='utf-8'))
print(f'Chunks: {len(data[\"chunks\"])}')
print(f'First chunk ID: {data[\"chunks\"][0][\"id\"]}')
print(f'ID type: {type(data[\"chunks\"][0][\"id\"])}')
"
```

**R√©sultat attendu :**
```
Chunks: 1010
First chunk ID: chunk_0
ID type: <class 'str'>
```

üí° **Note** : Une fois le JSON corrig√©, passez directement √† l'√©tape 3 (Indexation) en utilisant `prepared/applicationsIA_mini_chunks_fixed.json`

---

## √âtape 3 : Indexation dans ChromaDB

### 3.1 Comprendre l'indexation vectorielle

L'indexation transforme vos chunks en **vecteurs num√©riques** (embeddings) qui capturent leur sens s√©mantique. Dyag utilise :
- **Sentence Transformers** (all-MiniLM-L6-v2 par d√©faut)
- **ChromaDB** pour le stockage vectoriel
- **Recherche par similarit√© cosinus**

### 3.2 Premi√®re indexation

**Commande CLI :**
```bash
# Indexer les chunks dans ChromaDB
dyag index-rag \
  prepared/applications_chunks.jsonl \
  --collection applications_ia \
  --chroma-path ./chroma_db \
  --embedding-model all-MiniLM-L6-v2 \
  --batch-size 100 \
  --reset \
  --verbose
```

**Param√®tres expliqu√©s :**
- `--collection applications_ia` : Nom de la collection ChromaDB
- `--chroma-path ./chroma_db` : O√π stocker la base vectorielle
- `--embedding-model all-MiniLM-L6-v2` : Mod√®le d'embeddings (l√©ger et rapide)
- `--batch-size 100` : Indexer par batches de 100 chunks
- `--reset` : Efface la collection si elle existe (‚ö†Ô∏è attention en production!)
- `--verbose` : Affiche la progression

**üìä Utilisation via MCP :**
```json
{
  "tool": "dyag_index_rag",
  "arguments": {
    "input": "prepared/applications_chunks.jsonl",
    "collection": "applications_ia",
    "chroma_path": "./chroma_db",
    "embedding_model": "all-MiniLM-L6-v2",
    "batch_size": 100,
    "reset": true
  }
}
```
*‚úÖ Cette commande MCP existe d√©j√†*

### 3.3 V√©rification de l'indexation

**Commande CLI (Python) :**
```python
# V√©rifier que l'indexation a fonctionn√©
python -c "
import chromadb
client = chromadb.PersistentClient(path='./chroma_db')
collection = client.get_collection('applications_ia')
print(f'Nombre de documents index√©s: {collection.count()}')

# Tester une recherche simple
results = collection.query(
    query_texts=['application transport routier'],
    n_results=3
)
print(f'\\nTop 3 r√©sultats pour \"application transport routier\":')
for i, (doc, dist) in enumerate(zip(results['documents'][0], results['distances'][0]), 1):
    print(f'{i}. Distance: {dist:.3f}')
    print(f'   Extrait: {doc[:100]}...')
"
```

**R√©sultat attendu :**
```
Nombre de documents index√©s: 45

Top 3 r√©sultats pour "application transport routier":
1. Distance: 0.234
   Extrait: Application 6tzen - outil national de dematerialisation des demarches des transports routiers...
2. Distance: 0.456
   Extrait: Application RNTR - registre national des transports routiers...
3. Distance: 0.578
   Extrait: ...
```

**üí° Conseil :** Une distance < 0.5 indique une bonne similarit√© s√©mantique.

---

## √âtape 4 : Configuration du LLM

### 4.1 Choix du provider

| Provider | Co√ªt | Qualit√© | Vitesse | Setup |
|----------|------|---------|---------|-------|
| **Ollama** (local) | **GRATUIT** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | Facile |
| **OpenAI GPT-4** | ~$0.01/question | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Tr√®s facile |
| **Anthropic Claude** | ~$0.015/question | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | Facile |

**Recommandation :** Commencez avec **Ollama** (gratuit) pour le d√©veloppement et les tests.

### 4.2 Configuration Ollama (GRATUIT)

```bash
# 1. Installer Ollama
# Windows/Mac/Linux : https://ollama.com/download

# 2. Installer un mod√®le
ollama pull llama3.2

# 3. V√©rifier qu'il fonctionne
ollama run llama3.2 "Bonjour"

# 4. Configurer .env
echo "LLM_PROVIDER=ollama" >> .env
echo "LLM_MODEL=llama3.2" >> .env
echo "OLLAMA_BASE_URL=http://localhost:11434" >> .env
```

### 4.3 Configuration OpenAI (PAYANT)

```bash
# 1. Obtenir une cl√© API sur https://platform.openai.com/api-keys

# 2. Configurer .env
echo "LLM_PROVIDER=openai" >> .env
echo "OPENAI_API_KEY=sk-proj-votre-cl√©" >> .env
```

### 4.4 Configuration Anthropic Claude (PAYANT)

```bash
# 1. Obtenir une cl√© API sur https://console.anthropic.com/

# 2. Configurer .env
echo "LLM_PROVIDER=anthropic" >> .env
echo "ANTHROPIC_API_KEY=sk-ant-votre-cl√©" >> .env
```

### 4.5 Test de configuration

**Commande CLI :**
```bash
# Tester la connexion LLM
python -c "
from dyag.llm_providers import LLMProviderFactory
provider = LLMProviderFactory.create_provider()
print(f'Provider: {provider.get_model_name()}')
response = provider.generate('Dis bonjour en une phrase')
print(f'R√©ponse: {response}')
"
```

**R√©sultat attendu :**
```
Provider: llama3.2 (Ollama)
R√©ponse: Bonjour ! Comment puis-je vous aider aujourd'hui ?
```

---

## √âtape 5 : Interrogation du RAG

### 5.1 Premi√®re requ√™te simple

**Commande CLI :**
```bash
# Poser une question au RAG
dyag query-rag \
  "Qu'est-ce que l'application 6tzen ?" \
  --collection applications_ia \
  --n-chunks 5 \
  --verbose
```

**Param√®tres expliqu√©s :**
- `"Qu'est-ce que l'application 6tzen ?"` : La question
- `--collection applications_ia` : Collection ChromaDB √† interroger
- `--n-chunks 5` : R√©cup√©rer les 5 chunks les plus pertinents
- `--verbose` : Afficher les chunks r√©cup√©r√©s et la source

**üìä Utilisation via MCP :**
```json
{
  "tool": "dyag_rag_query",
  "arguments": {
    "question": "Qu'est-ce que l'application 6tzen ?",
    "collection": "applications_ia",
    "n_chunks": 5
  }
}
```
*‚úÖ Cette commande MCP existe d√©j√†*

**R√©sultat attendu :**
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    R√âSULTATS DE LA REQU√äTE RAG               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

Question: Qu'est-ce que l'application 6tzen ?

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Chunks r√©cup√©r√©s (5):
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

[1] Distance: 0.234 | Source: application_1238
Application 6tzen - outil national de dematerialisation des
demarches des transports routiers. Statut: en production.
La dematerialisation des procedures administratives du registre
des entreprises de transport par route...

[2] Distance: 0.456 | Source: application_1238_descriptif
Descriptif d√©taill√©: la dematerialisation s'inscrit dans le
cadre du programme gouvernemental de simplification...

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
R√©ponse g√©n√©r√©e:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

L'application 6tzen est l'outil national de d√©mat√©rialisation
des d√©marches des transports routiers, actuellement en production.
Elle permet aux entreprises de transport routier d'effectuer leurs
d√©marches administratives en ligne, incluant les demandes
d'autorisation d'exercer, le renouvellement de licences, et les
demandes de copies conformes.

Les principaux avantages pour les usagers sont:
- Gain de temps lors du remplissage des dossiers
- Suivi simplifi√© de l'√©tat des demandes
- Instruction facilit√©e gr√¢ce aux √©changes en ligne
- Diminution globale des d√©lais de traitement

Source: application_1238
```

### 5.2 Questions avanc√©es

**Exemples de questions √† tester :**

```bash
# Question sur le statut
dyag query-rag "Quelles applications sont en production ?" --collection applications_ia

# Question sur un domaine m√©tier
dyag query-rag "Liste les applications du domaine biodiversit√©" --collection applications_ia

# Question comparative
dyag query-rag "Quelle est la diff√©rence entre 6tzen et SINP ?" --collection applications_ia

# Question avec contexte
dyag query-rag "Qui sont les acteurs responsables de 6tzen ?" --collection applications_ia
```

### 5.3 Ajuster le nombre de chunks

Le param√®tre `--n-chunks` (ou `n_chunks` pour MCP) est crucial :

- **3 chunks** : Rapide, risque de manquer du contexte
- **5 chunks** : ‚≠ê **Recommand√©** - Bon √©quilibre
- **10 chunks** : Plus de contexte, mais plus lent et risque de "bruit"
- **20 chunks** : Maximum, pour questions tr√®s larges

**Test de sensibilit√© :**
```bash
# Tester avec diff√©rents nombres de chunks
for n in 3 5 10; do
  echo "=== Test avec $n chunks ==="
  dyag query-rag "Qu'est-ce que 6tzen ?" --collection applications_ia --n-chunks $n
done
```

---

## √âtape 6 : √âvaluation de la qualit√©

### 6.1 Cr√©er un dataset d'√©valuation

Un bon dataset d'√©valuation contient des paires question/r√©ponse de r√©f√©rence.

**Format JSONL attendu :**
```json
{"messages": [{"role": "system", "content": "..."}, {"role": "user", "content": "Qu'est-ce que 6tzen ?"}, {"role": "assistant", "content": "L'application 6tzen est..."}]}
```

**Commande CLI pour cr√©er le dataset :**
```bash
# Cr√©er un dataset d'√©valuation automatiquement
dyag markdown-to-rag \
  examples/test-mygusi/applicationsIA_mini_normalized.json \
  --output evaluation/test_dataset.jsonl \
  --num-questions 20 \
  --question-types factual,comparative,listing \
  --verbose
```

**üìä Utilisation via MCP :**
```json
{
  "tool": "dyag_create_rag",
  "arguments": {
    "input": "examples/test-mygusi/applicationsIA_mini_normalized.json",
    "output": "evaluation/test_dataset.jsonl",
    "num_questions": 20,
    "question_types": ["factual", "comparative", "listing"]
  }
}
```
*‚ö†Ô∏è Note: Cette commande MCP **n'existe pas encore** et doit √™tre ajout√©e*

### 6.2 √âvaluation avec le dataset

**Commande CLI :**
```bash
# √âvaluer le RAG sur le dataset de test
dyag evaluate-rag \
  evaluation/test_dataset.jsonl \
  --collection applications_ia \
  --output evaluation/results.json \
  --metrics all \
  --verbose
```

**üìä Utilisation via MCP :**
```json
{
  "tool": "dyag_evaluate_rag",
  "arguments": {
    "dataset": "evaluation/test_dataset.jsonl",
    "collection": "applications_ia",
    "output": "evaluation/results.json"
  }
}
```
*‚úÖ Cette commande MCP existe d√©j√†*

**R√©sultat attendu :**
```json
{
  "total_questions": 20,
  "correct_answers": 17,
  "accuracy": 0.85,
  "average_confidence": 0.78,
  "average_retrieval_time_ms": 145,
  "average_generation_time_ms": 2340,
  "metrics": {
    "factual_accuracy": 0.90,
    "completeness": 0.82,
    "relevance": 0.88
  },
  "errors": [
    {
      "question": "Combien d'applications sont en construction ?",
      "expected": "5 applications",
      "got": "Je ne trouve pas cette information",
      "reason": "Missing aggregation capability"
    }
  ]
}
```

### 6.3 Analyse des r√©sultats

**M√©triques cl√©s :**

| M√©trique | Cible | Signification |
|----------|-------|---------------|
| **Accuracy** | >80% | % de r√©ponses correctes |
| **Precision** | >75% | % d'informations pertinentes dans la r√©ponse |
| **Recall** | >70% | % d'informations importantes retrouv√©es |
| **Latence** | <3s | Temps de r√©ponse total |

**Commande pour visualiser les erreurs :**
```bash
# Examiner les erreurs
python -c "
import json
results = json.load(open('evaluation/results.json'))
print(f'Taux de r√©ussite: {results[\"accuracy\"]*100:.1f}%')
print(f'\\nErreurs ({len(results[\"errors\"])}):\\n')
for err in results['errors']:
    print(f'Q: {err[\"question\"]}')
    print(f'Attendu: {err[\"expected\"]}')
    print(f'Obtenu: {err[\"got\"]}')
    print(f'Raison: {err[\"reason\"]}\\n')
"
```

---

## √âtape 7 : Am√©lioration it√©rative

### 7.1 Identifier les probl√®mes courants

Bas√© sur l'√©valuation, vous pouvez avoir :

**Probl√®me 1 : Retrieval incomplet**
- Sympt√¥me : R√©ponses type "Je ne trouve pas cette information"
- Solution : Augmenter `--n-chunks` ou am√©liorer le chunking

**Probl√®me 2 : R√©ponses hors sujet**
- Sympt√¥me : Le RAG r√©pond √† c√¥t√© de la question
- Solution : Am√©liorer les prompts syst√®me ou changer de mod√®le LLM

**Probl√®me 3 : Informations fragment√©es**
- Sympt√¥me : R√©ponses incompl√®tes ou d√©cousues
- Solution : Augmenter `--overlap` dans le chunking

**Probl√®me 4 : Latence √©lev√©e**
- Sympt√¥me : >5s par requ√™te
- Solution : R√©duire `--n-chunks` ou utiliser un mod√®le plus rapide

### 7.2 Cycle d'am√©lioration

```bash
# 1. Analyser les r√©sultats d'√©valuation
cat evaluation/results.json

# 2. Ajuster le chunking si n√©cessaire
dyag prepare-rag \
  examples/test-mygusi/applicationsIA_mini_normalized.json \
  --output prepared/applications_chunks_v2.jsonl \
  --chunk-size 800 \        # R√©duit de 1000
  --overlap 300 \            # Augment√© de 200
  --chunk-strategy semantic

# 3. R√©-indexer
dyag index-rag \
  prepared/applications_chunks_v2.jsonl \
  --collection applications_ia_v2 \
  --reset

# 4. Re-tester
dyag evaluate-rag \
  evaluation/test_dataset.jsonl \
  --collection applications_ia_v2 \
  --output evaluation/results_v2.json

# 5. Comparer les r√©sultats
python -c "
import json
v1 = json.load(open('evaluation/results.json'))
v2 = json.load(open('evaluation/results_v2.json'))
print(f'V1 Accuracy: {v1[\"accuracy\"]*100:.1f}%')
print(f'V2 Accuracy: {v2[\"accuracy\"]*100:.1f}%')
print(f'Am√©lioration: {(v2[\"accuracy\"] - v1[\"accuracy\"])*100:+.1f}%')
"
```

### 7.3 Matrice d'optimisation

| Si le probl√®me est... | Alors ajuster... | Valeur sugg√©r√©e |
|----------------------|------------------|-----------------|
| Retrieval faible | `--n-chunks` | 5 ‚Üí 10 |
| Trop de bruit | `--n-chunks` | 10 ‚Üí 5 |
| Chunks trop grands | `--chunk-size` | 1000 ‚Üí 700 |
| Chunks trop petits | `--chunk-size` | 700 ‚Üí 1200 |
| Fragmentation | `--overlap` | 200 ‚Üí 400 |
| Latence √©lev√©e | `--n-chunks` et `--chunk-size` | R√©duire les deux |
| Qualit√© LLM faible | Provider | Ollama ‚Üí GPT-4 |

---

## Annexes

### Annexe A : Commandes MCP disponibles

#### Commandes actuellement disponibles

| Commande CLI | Commande MCP | Status |
|--------------|--------------|---------|
| `dyag prepare-rag` | `dyag_prepare_rag` | ‚ö†Ô∏è **√Ä ajouter** |
| `dyag index-rag` | `dyag_index_rag` | ‚úÖ Disponible |
| `dyag query-rag` | `dyag_rag_query` | ‚úÖ Disponible |
| `dyag evaluate-rag` | `dyag_evaluate_rag` | ‚úÖ Disponible |
| `dyag markdown-to-rag` | `dyag_create_rag` | ‚ö†Ô∏è **√Ä ajouter** |
| `dyag analyze_training` | `dyag_analyze_training` | ‚úÖ Disponible |

#### Nouvelles commandes propos√©es (d√©tails dans le Journal)

Apr√®s analyse du workflow r√©el d'indexation (voir `doc/RAG_WORKFLOW_JOURNAL.md`), voici les **8 modules prioritaires** √† d√©velopper :

| Module | Priorit√© | Probl√®me r√©solu | MCP |
|--------|----------|-----------------|-----|
| `dyag fix-chunk-ids` | ‚ú® P0 | Conversion manuelle IDs num√©riques ‚Üí strings | `dyag_fix_chunk_ids` |
| `dyag markdown-to-rag` | ‚ú® P0 | Pipeline 3 √©tapes ‚Üí 1 commande | `dyag_markdown_to_rag` |
| `dyag test-rag` | ‚ú® P0 | Erreurs Unicode Windows | `dyag_test_rag` |
| `dyag create-eval-dataset` | ‚≠ê P1 | Cr√©ation manuelle dataset | `dyag_create_eval_dataset` |
| `dyag rag-stats` | ‚≠ê P1 | Pas de vue d'ensemble syst√®me | `dyag_rag_stats` |
| `dyag validate-chunks` | üìã P2 | D√©tection tardive probl√®mes | `dyag_validate_chunks` |
| `dyag compare-rag` | üìä P2 | Comparaison configurations | `dyag_compare_rag` |
| `dyag export-rag` / `import-rag` | üíæ P2 | Sauvegarde/partage | `dyag_export_rag` |

**Exemple de workflow simplifi√© avec les nouveaux modules** :
```bash
# Au lieu de 7 √©tapes manuelles actuelles
dyag markdown-to-rag file.md --collection name --chunk-size 1000 --reset
dyag rag-stats --collection name
dyag create-eval-dataset --collection name --output eval.jsonl --num-questions 50
dyag test-rag --collection name --question "..." --no-emoji
dyag evaluate-rag eval.jsonl --collection name
```

üìñ **Voir** : `doc/RAG_WORKFLOW_JOURNAL.md` pour les sp√©cifications d√©taill√©es de chaque module

### Annexe B : Structure des fichiers g√©n√©r√©s

```
projet/
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ test-mygusi/
‚îÇ       ‚îî‚îÄ‚îÄ applicationsIA_mini_normalized.json  # ‚Üê Source
‚îú‚îÄ‚îÄ prepared/
‚îÇ   ‚îú‚îÄ‚îÄ applications_chunks.jsonl                # ‚Üê Chunks
‚îÇ   ‚îî‚îÄ‚îÄ applications_chunks_v2.jsonl             # ‚Üê Chunks optimis√©s
‚îú‚îÄ‚îÄ chroma_db/                                   # ‚Üê Base vectorielle
‚îÇ   ‚îú‚îÄ‚îÄ applications_ia/
‚îÇ   ‚îî‚îÄ‚îÄ applications_ia_v2/
‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset.jsonl                       # ‚Üê Questions de test
‚îÇ   ‚îú‚îÄ‚îÄ results.json                             # ‚Üê R√©sultats v1
‚îÇ   ‚îî‚îÄ‚îÄ results_v2.json                          # ‚Üê R√©sultats v2
‚îî‚îÄ‚îÄ .env                                         # ‚Üê Configuration
```

### Annexe C : Troubleshooting

**Probl√®me : "No module named 'chromadb'"**
```bash
# Solution:
pip install -r requirements-rag.txt
```

**Probl√®me : "Collection not found"**
```bash
# Solution: R√©-indexer
dyag index-rag prepared/applications_chunks.jsonl --collection applications_ia --reset
```

**Probl√®me : "Ollama connection refused"**
```bash
# Solution: V√©rifier qu'Ollama est d√©marr√©
ollama list
# Si non d√©marr√©, lancer:
ollama serve
```

**Probl√®me : "OpenAI API key not found"**
```bash
# Solution: V√©rifier .env
cat .env | grep OPENAI_API_KEY
# Si absent:
echo "OPENAI_API_KEY=sk-proj-votre-cl√©" >> .env
```

### Annexe D : Optimisations avanc√©es

#### D.1 Utiliser un meilleur mod√®le d'embeddings

```bash
# Mod√®le plus performant mais plus lourd
dyag index-rag \
  prepared/applications_chunks.jsonl \
  --collection applications_ia_advanced \
  --embedding-model all-mpnet-base-v2 \  # Plus pr√©cis
  --reset
```

#### D.2 Chunking hybride personnalis√©

```python
# Script Python personnalis√© pour chunking avanc√©
from dyag.commands.prepare_rag import prepare_for_rag

# Charger les donn√©es
import json
data = json.load(open('examples/test-mygusi/applicationsIA_mini_normalized.json'))

# Chunking personnalis√©
chunks = []
for app in data['applicationsia mini']:
    # Chunk 1: Vue d'ensemble
    chunk1 = {
        'id': f"app_{app['id']}_overview",
        'content': f"Application: {app['nom']}\\n{app.get('nom long', '')}\\nStatut: {app.get('statut si', '')}",
        'metadata': {'app_id': app['id'], 'type': 'overview'}
    }
    chunks.append(chunk1)

    # Chunk 2: Descriptif d√©taill√©
    if 'descriptif' in app:
        chunk2 = {
            'id': f"app_{app['id']}_descriptif",
            'content': f"Application {app['nom']}: {app['descriptif']}",
            'metadata': {'app_id': app['id'], 'type': 'descriptif'}
        }
        chunks.append(chunk2)

# Sauvegarder
import jsonlines
with jsonlines.open('prepared/custom_chunks.jsonl', 'w') as writer:
    writer.write_all(chunks)
```

#### D.3 R√©-ranking des r√©sultats

```python
# Impl√©menter un r√©-ranking personnalis√©
from dyag.rag_query import RAGQuerySystem

rag = RAGQuerySystem(collection_name='applications_ia')
question = "Qu'est-ce que 6tzen ?"

# R√©cup√©rer plus de chunks (20 au lieu de 5)
results = rag.query(question, n_chunks=20)

# R√©-ranker avec un score personnalis√©
def rerank_score(chunk, question):
    # Score bas√© sur la pr√©sence de mots-cl√©s importants
    keywords = ['6tzen', 'transport', 'routier', 'dematerialisation']
    score = sum(1 for kw in keywords if kw.lower() in chunk.lower())
    return score

# Trier et prendre le top 5
reranked = sorted(results, key=lambda c: rerank_score(c['content'], question), reverse=True)[:5]
```

---

## üéØ Checklist de r√©ussite

Votre RAG est de qualit√© si :

- [ ] **Accuracy ‚â• 80%** sur le dataset de test
- [ ] **Latence < 3s** par requ√™te (moyenne)
- [ ] **Pr√©cision des sources** : Toutes les r√©ponses citent correctement les sources
- [ ] **Gestion des absences** : R√©pond "Je ne sais pas" quand l'info n'existe pas
- [ ] **Pas d'hallucinations** : Ne r√©pond que sur les donn√©es index√©es
- [ ] **Consistance** : M√™me question = m√™me r√©ponse (√† variations stylistiques pr√®s)
- [ ] **Scalabilit√©** : Fonctionne avec 100+ applications

---

## üìö Ressources compl√©mentaires

- [Documentation ChromaDB](https://docs.trychroma.com/)
- [Sentence Transformers Models](https://www.sbert.net/docs/pretrained_models.html)
- [Guide Ollama](https://ollama.com/library)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Anthropic Claude Documentation](https://docs.anthropic.com/)

---

**Derni√®re mise √† jour** : 2025-01-16
**Version du guide** : 1.0
**Auteur** : √âquipe Dyag

---

**Dyag** - RAG de qualit√©, commande par commande! üöÄüìö
